# ===============================
# Dareloom Hub - robots.txt (SEO + AI Protection)
# ===============================
# Auto-generated by Dareloom Build Script
# Last updated: 2025-10-13
# Location: https://dareloom.fun/robots.txt
# Purpose:
#   - Block known AI and scraper bots
#   - Allow major search engines
#   - Improve crawl efficiency and SEO health
# ===============================

# -------------------------------
# 1) Block AI & Scraper Bots (best-effort)
# -------------------------------
User-agent: GPTBot
Disallow: /

User-agent: ClaudeBot
Disallow: /

User-agent: PerplexityBot
Disallow: /

User-agent: Diffbot
Disallow: /

User-agent: OmgiliBot
Disallow: /

User-agent: anthropic-ai
Disallow: /

User-agent: ChatGPT
Disallow: /

User-agent: FacebookBot
Disallow: /

User-agent: Google-Extended
Disallow: /

User-agent: meta-externalagent
Disallow: /

# -------------------------------
# 2) Major Search Engines (SEO Optimized)
# -------------------------------
User-agent: Googlebot
Allow: /
Disallow: /admin/
Disallow: /private/

User-agent: Bingbot
Allow: /

User-agent: Yandex
Allow: /

# -------------------------------
# 3) Default Rules (for all other bots)
# -------------------------------
User-agent: *
Disallow: /admin/
Disallow: /api/
Disallow: /node_modules/
Disallow: /scripts/
Disallow: /private/
Disallow: /temp/
Disallow: /*?*sort=*
Disallow: /*?*filter=*
Disallow: /*?*session=*
Disallow: /*?*ref=*
Disallow: /*?*utm_*

Crawl-delay: 5

# -------------------------------
# Sitemap Location
# -------------------------------
Sitemap: https://dareloom.fun/sitemap.xml
Sitemap: https://dareloom.fun/sitemap-video.xml
Sitemap: https://dareloom.fun/sitemap-seo.xml

# ===============================
# End of File
# ===============================
